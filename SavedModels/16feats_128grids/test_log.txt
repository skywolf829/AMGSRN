Model was trained with TCNN and TCNN is available.
APMGSRN(
  (encoder): APMG_encoder()
  (decoder): Network(n_input_dims=16, n_output_dims=1, seed=1337, dtype=torch.float16, hyperparams={'encoding': {'offset': 0.0, 'otype': 'Identity', 'scale': 1.0}, 'network': {'activation': 'ReLU', 'n_hidden_layers': 2, 'n_neurons': 64, 'otype': 'FullyFusedMLP', 'output_activation': 'None'}, 'otype': 'NetworkWithInputEncoding'})
)
Extents: 0,512,0,512,0,512
Chunk 0,512,0,512,0,512
Extents: 0,512,0,512,512,1000
Chunk 0,512,0,512,512,1000
Extents: 0,512,512,1000,0,512
Chunk 0,512,512,1000,0,512
Extents: 0,512,512,1000,512,1000
Chunk 0,512,512,1000,512,1000
Extents: 512,1000,0,512,0,512
Chunk 512,1000,0,512,0,512
Extents: 512,1000,0,512,512,1000
Chunk 512,1000,0,512,512,1000
Extents: 512,1000,512,1000,0,512
Chunk 512,1000,512,1000,0,512
Extents: 512,1000,512,1000,512,1000
Chunk 512,1000,512,1000,512,1000
Extents: 0,768,0,768,0,768
Data: torch.Size([1, 1, 768, 768, 768]) from full extents (1000, 1000, 1000). IO time loading data:  1.6932
Chunk 0,768,0,768,0,768 SSE: 54434.3359375
Extents: 0,768,0,768,768,1000
Data: torch.Size([1, 1, 768, 768, 232]) from full extents (1000, 1000, 1000). IO time loading data:  0.5690
Chunk 0,768,0,768,768,1000 SSE: 2512.968017578125
Extents: 0,768,768,1000,0,768
Data: torch.Size([1, 1, 768, 232, 768]) from full extents (1000, 1000, 1000). IO time loading data:  0.5820
Chunk 0,768,768,1000,0,768 SSE: 2372.34130859375
Extents: 0,768,768,1000,768,1000
Data: torch.Size([1, 1, 768, 232, 232]) from full extents (1000, 1000, 1000). IO time loading data:  0.2423
Chunk 0,768,768,1000,768,1000 SSE: 0.0
Extents: 768,1000,0,768,0,768
Data: torch.Size([1, 1, 232, 768, 768]) from full extents (1000, 1000, 1000). IO time loading data:  0.5780
Chunk 768,1000,0,768,0,768 SSE: 2051.75634765625
Extents: 768,1000,0,768,768,1000
Data: torch.Size([1, 1, 232, 768, 232]) from full extents (1000, 1000, 1000). IO time loading data:  0.2250
Chunk 768,1000,0,768,768,1000 SSE: 1048.213134765625
Extents: 768,1000,768,1000,0,768
Data: torch.Size([1, 1, 232, 232, 768]) from full extents (1000, 1000, 1000). IO time loading data:  0.2390
Chunk 768,1000,768,1000,0,768 SSE: 0.0
Extents: 768,1000,768,1000,768,1000
Data: torch.Size([1, 1, 232, 232, 232]) from full extents (1000, 1000, 1000). IO time loading data:  0.1120
Chunk 768,1000,768,1000,768,1000 SSE: 0.0
MSE: tensor([6.2420e-05], device='cuda:0'), shape [1000, 1000, 1000]
Data min/max: 3.523324358839197e-27/0.5003551840782166
PSNR:  36.032
Time for 100 passes with batch size 8388608: 1.7570090293884277
Throughput: 477436817.89272714 points per second
 0.91GB of memory used during test.
