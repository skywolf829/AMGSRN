<html lang="en">
	<head>
		<title>AMGSRN Neural Volume Render</title>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0">
		<link rel="stylesheet" href="css/style.css">
	</head>
	<body>
		
		<div class="container", id="container">
			<div class="renderer-container" id="renderer-container">

			<div>
				<div>Transfer function</div>
				0.0<img id="transferFunctionImg"/>1.0
			</div>
			</div>
			
			
		</div>
		<script src="./js/three.min.js"></script>
		<script src="./js/Detector.js"></script>
		<script src="./js/stats.min.js"></script>
		<script src="./js/OrbitControls.js"></script>
		<script src="./js/dat.gui.min.js"></script>
		<script src="./js/jszip.min.js"></script>

		<script id="fragmentShaderFirstPass" type="x-shader/x-fragment">
			varying vec3 worldSpaceCoords;

			void main()
			{
				//The fragment's world space coordinates as fragment output.
				gl_FragColor = vec4( worldSpaceCoords.x, worldSpaceCoords.y, worldSpaceCoords.z, 1 );
			}
		</script>
		<script id="vertexShaderFirstPass" type="x-shader/x-vertex">
			varying vec3 worldSpaceCoords;
			
			uniform float boxWidth;
			uniform float boxHeight;
			uniform float boxDepth;

			void main()
			{
				//Set the world space coordinates of the back faces vertices as output.
				worldSpaceCoords = position + vec3(boxWidth / 2.0, boxHeight / 2.0, boxDepth / 2.0); //move it from [-0.5;0.5] to [0,1]
				gl_Position = projectionMatrix * modelViewMatrix * vec4( position, 1.0 );
			}
		</script>
		<script id="fragmentShaderSecondPass" type="x-shader/x-fragment">
			// precision mediump float;
			varying vec3 worldSpaceCoords;
			varying vec4 projectedCoords;
			uniform sampler2D tex, transferTex;
			uniform float steps;
			uniform float alphaCorrection;
			uniform float boxWidth;
			uniform float boxHeight;
			uniform float boxDepth;

			// Variables for the neural network
			uniform mediump sampler3D volumeTexture; 
			uniform int numLayers;
			uniform int nodesPerLayer;
			uniform mat4 transformationMatrices[32];
			uniform sampler2D mlpFloats;
			uniform int numGrids;
			uniform int featuresPerGrid;

			// The maximum distance through our rendering volume is sqrt(3).
			// The maximum number of steps we take to travel a distance of 1 is 512.
			// ceil( sqrt(3) * 512 ) = 887
			// This prevents the back of the image from getting cut off when steps=512 & viewing diagonally.
			const int MAX_STEPS = 887;
			
			float sampleVolume(vec3 position) {
				// Sample the 3D texture using the texture coordinates
				float val = texture(volumeTexture, position).r;
				return val;
			}

			vec4 transferFunction(float val){
				vec4 color = texture2D(transferTex, vec2(val, 1.0));
				return color;
			}

			vec4 network_inference_with_transfer_function(vec3 position){
				vec3 p = vec3(position.x*2.0 - 1.0, position.y*2.0 - 1.0, position.z*2.0 - 1.0);
				float features[32];
				bool isWithinBounds = false;
				vec4 p_t;
				float x_offset = 0.0;
				float x_rel = 0.0;
				float y_rel = 0.0;
				vec3 p_tex;
				float val;
				vec4 color;
				float temp = 0.0;
				// get feature vector for query point
				for (int i = 0; i < numGrids; i++) {
					p_t = transformationMatrices[i] * vec4(p, 1.0);
					isWithinBounds = p_t.x >= -1.0 && p_t.x <= 1.0 &&
						p_t.y >= -1.0 && p_t.y <= 1.0 &&
						p_t.z >= -1.0 && p_t.z <= 1.0;
					x_offset = float(i) / float(numGrids);
					x_rel = p_t.x / float(numGrids);
					y_rel = p_t.y / float(featuresPerGrid);
					for (int c = 0; c < featuresPerGrid; c++){
						if(isWithinBounds){
							p_tex = vec3(x_offset, float(c) / float(featuresPerGrid), 0.0) + 
								vec3(x_rel, y_rel, p_t.z);
							features[c+featuresPerGrid*i] = sampleVolume(p_tex);
							temp += 1.0;
						}
						else{
							features[c+featuresPerGrid*i] = 0.0;
						}
					}
				}
				// MLP forward pass
				float layer_output[64];
				int num_weights = featuresPerGrid*numGrids*nodesPerLayer + 
					(numLayers-1)*nodesPerLayer*nodesPerLayer + nodesPerLayer;
				
				for(int l = 1; l < numLayers; l++){

				}
				//val = sampleVolume(position+vec3(0.0, 0.0, 0.0));
				color = transferFunction(temp/10.0);
				return color;
			
			}


			void main( void ) {

				//Transform the coordinates it from [-1;1] to [0;1]
				vec2 texc = vec2(((projectedCoords.x / projectedCoords.w) + 1.0 ) / 2.0,
								((projectedCoords.y / projectedCoords.w) + 1.0 ) / 2.0 );

				//The back position is the world space position stored in the texture.
				vec3 backPos = texture2D(tex, texc).xyz;

				//The front position is the world space position of the second render pass.
				vec3 frontPos = worldSpaceCoords;

				//Using NearestFilter for rtTexture mostly eliminates bad backPos values at the edges
				//of the cube, but there may still be no valid backPos value for the current fragment.
				if ((backPos.x == 0.0) && (backPos.y == 0.0))
				{
					gl_FragColor = vec4(0.0);
					return;
				}

				//The direction from the front position to back position.
				vec3 dir = backPos - frontPos;

				float rayLength = length(dir);

				//Calculate how long to increment in each step.
				float delta = 1.0 / steps;

				//The increment in each direction for each step.
				vec3 deltaDirection = normalize(dir) * delta;
				float deltaDirectionLength = length(deltaDirection);

				//Start the ray casting from the front position.
				vec3 currentPosition = frontPos;

				//The color accumulator.
				vec4 accumulatedColor = vec4(0.0);

				//The alpha value accumulated so far.
				float accumulatedAlpha = 0.0;

				//How long has the ray travelled so far.
				float accumulatedLength = 0.0;

				//If we have twice as many samples, we only need ~1/2 the alpha per sample.
				//Scaling by 256/10 just happens to give a good value for the alphaCorrection slider.
				float alphaScaleFactor = 25.6 * delta;

				vec4 colorSample;
				float alphaSample;

				//Perform the ray marching iterations
				for(int i = 0; i < MAX_STEPS; i++)
				{
					if(numGrids > 0 && featuresPerGrid > 0){

						colorSample = network_inference_with_transfer_function(currentPosition);
					}
					else{
						colorSample = vec4(1.0, 0.0, 0.0, 1.0);
					}

					//Allow the alpha correction customization.
					alphaSample = colorSample.a * alphaCorrection;

					//Applying this effect to both the color and alpha accumulation results in more realistic transparency.
					alphaSample *= (1.0 - accumulatedAlpha);

					//Scaling alpha by the number of steps makes the final color invariant to the step size.
					alphaSample *= alphaScaleFactor;

					//Perform the composition.
					accumulatedColor += colorSample * alphaSample;

					//Store the alpha accumulated so far.
					accumulatedAlpha += alphaSample;

					//Advance the ray.
					currentPosition += deltaDirection;
					accumulatedLength += deltaDirectionLength;

					//If the length traversed is more than the ray length, or if the alpha accumulated reaches 1.0 then exit.
					if(accumulatedLength >= rayLength || accumulatedAlpha >= 0.99 )
						break;
				}

				gl_FragColor  = accumulatedColor;
			}
		</script>

		<script id="vertexShaderSecondPass" type="x-shader/x-vertex">
			varying vec3 worldSpaceCoords;
			varying vec4 projectedCoords;
			
			uniform float boxWidth;
			uniform float boxHeight;
			uniform float boxDepth;
	
			void main()
			{
				worldSpaceCoords = (modelMatrix * vec4(position + vec3(boxWidth / 2.0, boxHeight / 2.0, boxDepth / 2.0), 1.0 )).xyz;
				gl_Position = projectionMatrix *  modelViewMatrix * vec4( position, 1.0 );
				projectedCoords =  projectionMatrix * modelViewMatrix * vec4( position, 1.0 );
			}
		</script>

		<script>
			if ( ! Detector.webgl ) Detector.addGetWebGLMessage();

			var container, stats;
			var camera, sceneFirstPass, sceneSecondPass, renderer;

			var clock = new THREE.Clock();
			var rtTexture, transferTexture;
			var cubeTextures = ['bonsai', 'foot', 'teapot'];
			var histogram = [];
			var guiControls;

			var materialSecondPass;
			init();
			animate();
			
			document.addEventListener('DOMContentLoaded', function() {
				const dropArea = document.getElementById('container');

				// Prevent default drag behaviors
				['dragenter', 'dragover', 'dragleave', 'drop'].forEach(eventName => {
					dropArea.addEventListener(eventName, preventDefaults, false);
				});

				function preventDefaults(e) {
					e.preventDefault();
					e.stopPropagation();
				}

				// Handle the drop event
				dropArea.addEventListener('drop', handleDrop, false);
			});

			async function handleDrop(e) {
				const dt = e.dataTransfer;
				const files = dt.files;

				if (files.length !== 1 || !files[0].name.endsWith('.zip')) {
					alert("Please drop exactly one .zip file.");
					return;
				}

				const zipFile = files[0];
				const zip = new JSZip();

				try {
					const content = await zip.loadAsync(zipFile);
					let jsonData = null;
					const binDataDict = {};

					const jsonFile = content.file("options.json");
					if (jsonFile) {
						const jsonText = await jsonFile.async("string");
						jsonData = JSON.parse(jsonText);
						console.log(jsonData);
					}

					const binFiles = Object.keys(content.files).filter(name => name.endsWith('.bin'));
					for (const binFileName of binFiles) {
						const binFile = content.file(binFileName);
						const binArrayBuffer = await binFile.async("arraybuffer");
						const floatArray = new Float32Array(binArrayBuffer);
						binDataDict[binFileName] = floatArray;
						console.log(`${binFileName}: ${floatArray.length} floats\n`);
					}

					setupShaderMaterial(jsonData, binDataDict);

				} catch (err) {
					console.error("Error reading ZIP file:", err);
				}
			}
			
			function generateRandom3DTexture(size) {
				const data = new Float32Array(size * size * size);
				for (let i = 0; i < size * size * size; i++) {
					data[i] = Math.random();
				}

				const texture = new THREE.Data3DTexture(data, size, size, size);
				texture.format = THREE.RedFormat;
				texture.type = THREE.FloatType;
				texture.minFilter = THREE.LinearFilter;
				texture.magFilter = THREE.LinearFilter;
				texture.unpackAlignment = 1;
				texture.needsUpdate = true;  // Ensures the texture is updated
				return texture;
			}

			async function setupShaderMaterial(jsonData, binDataDict) {
				console.log("Updating shader uniforms");
				// Update the feature grid 3Dtexture
				const feature_grids_raw = binDataDict['feature_grids.bin'];
				const num_grids = jsonData['n_grids'];
				const grid_size_str = jsonData['feature_grid_shape'].split(',');
				const grid_size = grid_size_str.map(Number);
				const el_per_grid = grid_size[0]*grid_size[1]*grid_size[2];
				console.log(num_grids + " " + grid_size)
				

				// Reorder the data
				const N = num_grids;
				const C = jsonData['n_features'];
				const D = grid_size[0];
				const H = grid_size[1];
				const W = grid_size[2];
				let reordered_data = new Float32Array(N * C * D * H * W);
				for (let n = 0; n < N; n++) {
					for (let c = 0; c < C; c++) {
						for (let d = 0; d < D; d++) {
							for (let h = 0; h < H; h++) {
								for (let w = 0; w < W; w++) {
									// Calculate the source and destination indices
									let srcIndex = n * (C * D * H * W) + c * (D * H * W) + d * (H * W) + h * W + w;
									let dstIndex = n * (D * C * H * W) + d * (C * H * W) + c * (H * W) + h * W + w;
									
									// Copy the data
									reordered_data[dstIndex] = feature_grids_raw[srcIndex];
								}
							}
						}
					}
				}
				const texture = new THREE.Data3DTexture(reordered_data, 
					N*grid_size[0], C*grid_size[1], grid_size[2]);
				texture.format = THREE.RedFormat;
				texture.type = THREE.FloatType;
				texture.minFilter = THREE.LinearFilter;
				texture.magFilter = THREE.LinearFilter;
				texture.unpackAlignment = 1;
				texture.needsUpdate = true;  // Ensures the texture is updated

				materialSecondPass.uniforms.volumeTexture.value = texture;//generateRandom3DTexture(32);

				// Update the number of layers
				materialSecondPass.uniforms.numLayers.value = jsonData['n_layers'];
				
				// Update the features per grid
				materialSecondPass.uniforms.featuresPerGrid.value = jsonData['n_features'];

				// Update the number of grids
				materialSecondPass.uniforms.numGrids.value = num_grids;

				// Update the nodes per layer
				materialSecondPass.uniforms.nodesPerLayer.value = jsonData['nodes_per_layer'];
				
				// update the transformation matrices
				let transformation_matrices = new Float32Array(16*256).fill(0);
				for(let i = 0; i < num_grids; i++){
					const o = 16*i;
					let q = binDataDict['_rotations.bin'].slice(4*i,4*(i+1));
					let s = binDataDict['_scales.bin'].slice(3*i,3*(i+1));
					let t = binDataDict['translations.bin'].slice(3*i,3*(i+1));
					for (let j = 0; j < s.length; j++){
						s[j] = Math.exp(s[j]);
					}
					const magnitude = Math.sqrt(q[0] * q[0] + q[1] * q[1] + q[2] * q[2] + q[3] * q[3]);
					if (magnitude > 0.0) {
						const invMagnitude = 1.0 / magnitude;
						q[0] *= invMagnitude;
						q[1] *= invMagnitude;
						q[2] *= invMagnitude;
						q[3] *= invMagnitude;
					}
					const wx = q[0] * q[3];
					const wy = q[1] * q[3];
					const wz = q[2] * q[3];
					const xx = q[0] * q[0];
					const xy = q[0] * q[1];
					const xz = q[0] * q[2];
					const yy = q[1] * q[1];
					const yz = q[1] * q[2];
					const zz = q[2] * q[2];

					transformation_matrices[o + 0] = s[0] * (1.0 - 2.0 * (yy + zz));
					transformation_matrices[o + 1] = s[1] * (2.0 * (xy - wz));
					transformation_matrices[o + 2] = s[2] * (2.0 * (xz + wy));
					transformation_matrices[o + 3] = t[0];

					transformation_matrices[o + 4] = s[0] * (2.0 * (xy + wz));
					transformation_matrices[o + 5] = s[1] * (1.0 - 2.0 * (xx + zz));
					transformation_matrices[o + 6] = s[2] * (2.0 * (yz - wx));    
					transformation_matrices[o + 7] = t[1];

					transformation_matrices[o + 8] = s[0] * (2.0 * (xz - wy));
					transformation_matrices[o + 9] = s[1] * (2.0 * (yz + wx));
					transformation_matrices[o + 10] = s[2] * (1.0 - 2.0 * (xx + yy));
					transformation_matrices[o + 11] = t[2];

					transformation_matrices[o + 12] = t[0];
					transformation_matrices[o + 13] = t[1];
					transformation_matrices[o + 14] = t[2];
					transformation_matrices[o + 15] = 1.0;
				}
				materialSecondPass.uniforms.transformationMatrices.value = transformation_matrices;
				
				// update the texture for mlp weights
				let mlp_array = binDataDict['decoder.0.linear.weight.bin'];
				for(let i = 1; i < jsonData['n_layers']; i++){
					mlp_array = [...mlp_array, ...binDataDict['decoder.'+i+'.linear.weight.bin']];
				}
				mlp_array = [...mlp_array, ...binDataDict['decoder.'+jsonData['n_layers']+'.weight.bin']];
				const mlp_texture = new THREE.DataTexture(mlp_array, 
					mlp_array.length, 1, THREE.RGBFormat, THREE.FloatType);
				mlp_texture.minFilter = THREE.NearestFilter;
				mlp_texture.magFilter = THREE.NearestFilter;
				mlp_texture.needsUpdate = true;  // Ensures the texture is updated
				materialSecondPass.uniforms.mlpFloats.value = mlp_array;


				materialSecondPass.needsUpdate = true;
			}
			
			function init() {

				//Parameters that can be modified.
				guiControls = new function() {
					this.model = 'bonsai';
					this.steps = 256.0;
					this.alphaCorrection = 1.0;
					this.color1 = "#00FA58";
					this.stepPos1 = 0.1;
					this.color2 = "#CC6600";
					this.stepPos2 = 0.7;
					this.color3 = "#F2F200";
					this.stepPos3 = 1.0;
				};

				container = document.getElementById( 'renderer-container' );

				camera = new THREE.PerspectiveCamera( 40, window.innerWidth / window.innerHeight, 0.01, 3000.0 );
				camera.position.z = 2.0;

				controls = new THREE.OrbitControls( camera, container );
				controls.target.set( 0.0, 0.0, 0.0 );


				//Load the 2D texture containing the Z slices.
				cubeTextures["bonsai"] = new THREE.TextureLoader().load("bonsai.raw.png");
				console.log(cubeTextures["bonsai"]);
				cubeTextures["teapot"] = new THREE.TextureLoader().load("teapot.raw.png");
				cubeTextures["foot"] = new THREE.TextureLoader().load("foot.raw.png");

				//Don't let it generate mipmaps to save memory and apply linear filtering to prevent use of LOD.
				cubeTextures['bonsai'].generateMipmaps = false;
				cubeTextures['bonsai'].minFilter = THREE.LinearFilter;
				cubeTextures['bonsai'].magFilter = THREE.LinearFilter;

				cubeTextures['teapot'].generateMipmaps = false;
				cubeTextures['teapot'].minFilter = THREE.LinearFilter;
				cubeTextures['teapot'].magFilter = THREE.LinearFilter;

				cubeTextures['foot'].generateMipmaps = false;
				cubeTextures['foot'].minFilter = THREE.LinearFilter;
				cubeTextures['foot'].magFilter = THREE.LinearFilter;


				var transferTexture = updateTransferFunction();

				var screenSize = new THREE.Vector2( window.innerWidth, window.innerHeight );
				//Use NearestFilter to eliminate interpolation.  At the cube edges, interpolated world coordinates
				//will produce bogus ray directions in the fragment shader, and thus extraneous colors.
				rtTexture = new THREE.WebGLRenderTarget(screenSize.x, screenSize.y, {
					minFilter: THREE.NearestFilter,
					magFilter: THREE.NearestFilter,
					wrapS: THREE.ClampToEdgeWrapping,
					wrapT: THREE.ClampToEdgeWrapping,
					format: THREE.RGBAFormat,
					type: THREE.FloatType,
					generateMipmaps: false,
					stencilBuffer: true,
				});

				// Normalized sizes of the cube's dimensions.
				// Format: [x, y, z] or [width, height, depth]
				// If the input data "cube" has dimensions 50 x 25 x 100, then boxSize should be [0.5, 0.25, 1.0]
				// Hardcoding to [1 ,1, 1] here because all input dataets are cubes. 
				const boxSize = [1, 1, 1]

				var materialFirstPass = new THREE.ShaderMaterial( {
					vertexShader: document.getElementById( 'vertexShaderFirstPass' ).textContent,
					fragmentShader: document.getElementById( 'fragmentShaderFirstPass' ).textContent,
					side: THREE.BackSide,
					uniforms: {
                        boxWidth: {
                            type: '1f',
                            value: boxSize[0],
                        },
                        boxHeight: {
                            type: '1f',
                            value: boxSize[1],
                        },
                        boxDepth: {
                            type: '1f',
                            value: boxSize[2],
                        },
                    },
				} );

				materialSecondPass = new THREE.ShaderMaterial( {
					vertexShader: document.getElementById( 'vertexShaderSecondPass' ).textContent,
					fragmentShader: document.getElementById( 'fragmentShaderSecondPass' ).textContent,
					side: THREE.FrontSide,
					uniforms: {	tex:  { type: "t", value: rtTexture.texture },
								cubeTex:  { type: "t", value: cubeTextures['bonsai'] },
								volumeTexture: {type: "t", value: generateRandom3DTexture(32) },
								transferTex:  { type: "t", value: transferTexture },
								steps : {type: "1f" , value: guiControls.steps },
								alphaCorrection : {type: "1f", value: guiControls.alphaCorrection },
								boxWidth: {type: '1f', value: boxSize[0] },
								boxHeight: {type: '1f', value: boxSize[1] },
								boxDepth: {type: '1f', value: boxSize[2] },
								numLayers: {value: 2},
								numGrids: {value: 0},
								featuresPerGrid: {value: 0},
								nodesPerLayer: {value: 32},
								transformationMatrices: {value: new Float32Array(16*128)}, // type is a matrix 4x4
								mlpFloats: {type: 't', value: new Float32Array(32*64+64*64+64)}
					}
				} );
				materialSecondPass.needsUpdate = true;

				sceneFirstPass = new THREE.Scene();
				sceneSecondPass = new THREE.Scene();

				var boxGeometry = new THREE.BoxGeometry(1.0, 1.0, 1.0);
				boxGeometry.doubleSided = true;

				var meshFirstPass = new THREE.Mesh( boxGeometry, materialFirstPass );
				var meshSecondPass = new THREE.Mesh( boxGeometry, materialSecondPass );

				sceneFirstPass.add( meshFirstPass );
				sceneSecondPass.add( meshSecondPass );

				renderer = new THREE.WebGLRenderer();
				container.appendChild( renderer.domElement );

				stats = new Stats();
				stats.domElement.style.position = 'absolute';
				stats.domElement.style.top = '0px';
				container.appendChild( stats.domElement );


				var gui = new dat.GUI();
				var modelSelected = gui.add(guiControls, 'model', [ 'bonsai', 'foot', 'teapot' ] );
				gui.add(guiControls, 'steps', 0.0, 512.0);
				gui.add(guiControls, 'alphaCorrection', 0.01, 5.0).step(0.01);

				modelSelected.onChange(function(value) { materialSecondPass.uniforms.cubeTex.value =  cubeTextures[value]; } );


				//Setup transfer function steps.
				var step1Folder = gui.addFolder('Step 1');
				var controllerColor1 = step1Folder.addColor(guiControls, 'color1');
				var controllerStepPos1 = step1Folder.add(guiControls, 'stepPos1', 0.0, 1.0);
				controllerColor1.onChange(updateTextures);
				controllerStepPos1.onChange(updateTextures);

				var step2Folder = gui.addFolder('Step 2');
				var controllerColor2 = step2Folder.addColor(guiControls, 'color2');
				var controllerStepPos2 = step2Folder.add(guiControls, 'stepPos2', 0.0, 1.0);
				controllerColor2.onChange(updateTextures);
				controllerStepPos2.onChange(updateTextures);

				var step3Folder = gui.addFolder('Step 3');
				var controllerColor3 = step3Folder.addColor(guiControls, 'color3');
				var controllerStepPos3 = step3Folder.add(guiControls, 'stepPos3', 0.0, 1.0);
				controllerColor3.onChange(updateTextures);
				controllerStepPos3.onChange(updateTextures);

				step1Folder.open();
				step2Folder.open();
				step3Folder.open();


				onWindowResize();

				window.addEventListener( 'resize', onWindowResize, false );

			}

			function updateTextures(value)
			{
				materialSecondPass.uniforms.transferTex.value = updateTransferFunction();
			}
			
			function updateTransferFunction()
			{
				var canvas = document.createElement('canvas');
				canvas.height = 20;
				canvas.width = 256;

				var ctx = canvas.getContext('2d');

				var grd = ctx.createLinearGradient(0, 0, canvas.width -1 , canvas.height - 1);
				grd.addColorStop(guiControls.stepPos1, guiControls.color1);
				grd.addColorStop(guiControls.stepPos2, guiControls.color2);
				grd.addColorStop(guiControls.stepPos3, guiControls.color3);

				ctx.fillStyle = grd;
				ctx.fillRect(0,0,canvas.width -1 ,canvas.height -1 );

				var img = document.getElementById("transferFunctionImg");
				img.src = canvas.toDataURL();
				img.style.width = "256 px";
				img.style.height = "128 px";

				transferTexture =  new THREE.Texture(canvas);
				transferTexture.wrapS = transferTexture.wrapT =  THREE.ClampToEdgeWrapping;
				transferTexture.needsUpdate = true;

				return transferTexture;
			}

			function onWindowResize( event ) {

				camera.aspect = window.innerWidth / window.innerHeight;
				camera.updateProjectionMatrix();

				renderer.setSize( window.innerWidth, window.innerHeight );
			}

			function animate() {

				requestAnimationFrame( animate );

				render();
				stats.update();
			}

			function render() {

				var delta = clock.getDelta();

				//Render first pass and store the world space coords of the back face fragments into the texture.
				renderer.setRenderTarget(rtTexture);
				renderer.render(sceneFirstPass, camera);
				renderer.setRenderTarget(null);

				//Render the second pass and perform the volume rendering.
				renderer.render(sceneSecondPass, camera);

				materialSecondPass.uniforms.steps.value = guiControls.steps;
				materialSecondPass.uniforms.alphaCorrection.value = guiControls.alphaCorrection;
			}

		</script>

	</body>
</html>
